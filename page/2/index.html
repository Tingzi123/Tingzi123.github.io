<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-OS文件管理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/29/OS文件管理/" class="article-date">
  <time datetime="2019-03-29T13:50:30.819Z" itemprop="datePublished">2019-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/29/OS文件管理/">操作系统-文件管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、 文件与文件系统<br>（1）文件的概念<br>文件指的是一组带标识的在逻辑上有完整意义的信息项（构成文件内容的基本单元）的序列，或者是相关联纪录的集合。文件存放在磁盘或磁带等存<br>储介质上。<br>文件是一个抽象机制，它提供了一种把信息保存在存储介质上，而且便于以后存取的方法，用户不必关心实现细节</p>
<p>（2）文件系统<br>• 是操作系统中统一管理信息资源的一种软件，管理文件的存储、检索、更新，提供安全可靠的共享和保护手段，并且方便用户使用</p>
<p>1.1 文件系统的功能：<br>（1）统一管理文件的存储空间，实施存储空间的分配与回收；<br>（2）为用户提供可见的文件逻辑结构，实现文件的按名存取；名字空间 → → → 存储空间<br>（3）对文件及文件目录的管理，这是文件系统最基本的功能，包括文件（目录）的建立、删除、读写等；<br>（4）提供操作系统与用户的接口（提供对文件的操作命令：信息存取、加工等）。</p>
<p>1.2 文件的分类<br>（1）按文件性质和用途分类<br>• 系统文件：<br>有关OS及有关系统所组成文件，不能直接访问<br>• 用户文件：<br>用户委托系统保存的文件<br>• 库文件：<br>标准子程序及常用应用程序组成文件，允许用户使用但不能修改</p>
<p>2、文件的结构和存取方式<br>（1）流式文件（无结构文件）：<br>• 构成文件的基本单位是字符，文件是有逻辑意义的、无结构的一串字符的集合。<br>• 管理简单，操作方便，但查找比较麻烦，对基本信息单位操作不多的文件比较适合用字符流的无结构方式，比如源程序文件。<br>（2）记录式文件（有结构文件）：<br>• 文件是由若干个记录组成，每个记录有一个键，可按键进行查找，每条记录有其内部结构。<br>• 方便用户进行各种操作比如添加、删除、修改、查找等</p>
<p>2.1 文件的存取方法<br>常用存取方法：<br>①顺序存取。<br>顺序存取是按照文件的逻辑地址顺序存取。比如当前读取的记录为Ri，则下一条读取的记录被自动确定为Ri的下一个相邻的记录Ri+1。<br>②随机存取。<br>允许用户根据记录的编号来存取文件的任一记录。前两种方法用于一般OS，下面方法适用数据库系统。<br>③按键存取。</p>
<p>2.2 文件的物理结构<br>– 文件系统中，文件存储设备通常分块，每块1k或者512字节或其他大小，与此对应，文件信息也被划分为与物理块大小相等的逻辑块<br>（1）连续结构（顺序）<br>– 文件的信息存放在若干连续的物理块中。系统为每个文件都建立一个文件控制块FCB。对于顺序文件，只要从FCB中得到文件的第一个块的物理块<br>号和文件长度，便可确定位置。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile1.png?raw=true" alt="Image text"><br>– 优点: 简单<br>• 支持顺序存取和随机存取<br>• 顺序存取速度快<br>• 所需的磁盘寻道次数和寻道时间最少</p>
<p>– 缺点:<br>• 不利于文件动态增长重新分配和移动<br>• 不利于文件插入和删除（大量移动）<br>• 外部碎片问题</p>
<p>（2）链接结构<br>– 一个文件的信息存放在若干不连续的物理块中，各块之间通过指针连接，前一个物理块指向下一个物理块<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile2.png?raw=true" alt="Image text"><br>– 优点：<br>• 提高了磁盘空间利用率,不存在外部碎片问题<br>• 有利于文件插入和删除<br>• 有利于文件动态扩充</p>
<p>– 缺点：<br>• 存取速度慢，不适于随机存取<br>• 可靠性问题，如指针出错<br>• 更多的寻道次数和寻道时间<br>• 链接指针占用一定的空间</p>
<p>（3）索引结构<br>• 一个文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构——索引表，并将这些块的块号存放在一个索引表中。<br>• 一个索引表就是磁盘块地址数组,其中第i个条目指向文件的第i块<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile3.png?raw=true" alt="Image text"></p>
<p>– 优点：<br>• 保持了链接结构的优点，又解决了其缺点：既能顺序存取，又能随机存取<br>• 满足了文件动态增长、插入删除的要求<br>• 能充分利用外存空间<br>– 缺点：<br>• 较多的寻道次数和寻道时间<br>• 索引表本身带来了系统开销<br>• 存取文件时至少访问存储器两次，一次是获得地址，一次是对物理块的访问。为了提高速度，将索引表放入内存，减少访问磁盘次数</p>
<p>文件的物理结构:<br>UNIX文件系统采用的是多级索引结构。每个文件的索引表为13个索引项，每项2个字节。最前面10项直接登记存放文件信息的物理块号（直接寻址）</p>
<p>如果文件大于10块，则利用第11项指向一个物理块，该块中最多可放256个文件物理块的块号（一次间接寻址）。对于更大的文件还可利用第12和第13项作为二次和三次间接寻址</p>
<p>– UNIX中采用了三级索引结构后，文件最大可达16兆个物理块<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile4.png?raw=true" alt="Image text"></p>
<p>文件存储介质：<br>（1）物理块<br>在文件系统中，文件的存储设备常常划分为若干大小相等的物理块。同时也将文件信息划分成相同大小的逻辑块，所有块统一编号以块为单位进行信息的存储、传输、分配</p>
<p>（2）磁带<br>永久保存大容量数据<br>– 顺序存取设备：前面的物理块被存取访问之后，才能存取后续的物理块的内容<br>– 存取速度较慢，主要用于后备存储，或存储不经常用的信息</p>
<p>（3）磁盘<br>– 直接（随机）存取设备：<br>• 存取磁盘上任一物理块的时间不依赖于该物理块所处的位置</p>
<p>完成过程由三个动作组成：<br>• 寻道（时间）：磁头移动定位到指定磁道<br>• 旋转延迟（时间）：等待指定扇区从磁头下旋转经过<br>• 数据传输（时间）：数据在磁盘与内存之间的实际传输</p>
<p>3、文件目录<br>3.1 基本概念<br>– 文件控制块（FCB）：<br>• 文件控制块是操作系统为管理文件而设置的数据结构，存放了为管理文件所需的所有有关信息。<br>• 文件控制块是文件存在的标志</p>
<p>– 文件目录：<br>• 把所有的FCB组织在一起，就构成了文件目录，即文件控制块的有序集合。<br>– 目录项：<br>• 构成文件目录的项目（目录项就是FCB）。<br>– 目录文件：<br>• 为了实现对文件目录的管理，通常将文件目录以文件的形式保存在外存，这个文件就叫目录文件</p>
<p>目录结构：<br>（1）一级目录结构<br>– 为所有文件建立一个目录文件（组成一线性表）<br>– 优点：<br>• 简单，易实现</p>
<p>– 缺点：<br>• 限制了用户对文件的命名<br>• 文件平均检索时间长</p>
<p>（2）二级目录结构<br>– 为解决一级目录文件目录命名冲突，并提高对目录文件检索速度而改进。<br>– 目录分为两级：<br>• 一级称为主文件目录（MFD），给出用户名，用户子目录所在的物理位置；<br>• 二级称为用户文件目录（UFD），给出该用户所有文件的FCB<br>– 使用二级目录可以解决文件重名和文件共享问题，并可以获得较高的搜索速度。</p>
<p>– 优点：解决了文件的重名问题和共享问题<br>用户名|文件名<br>查找时间降低<br>– 缺点：增加了系统开销<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile5.png?raw=true" alt="Image text"></p>
<p>（3）多级目录结构（树型目录）<br>– 优点：<br>• 层次结构清晰，便于管理和保护；有利于文件分类；解决重名问题；提高文件检索速度；能进行存取权限的控制 。<br>– 缺点：<br>• 查找一个文件按路径名逐层检查，由于每个文件都放在外存，多次访盘影响速度。</p>
<p>（4）文件目录改进<br>– 为加快目录检索可采用目录项分解法：把FCB分成两部分：<br>– 符号目录顶<br>文件名，文件号<br>– 基本目录项<br>除文件名外的所有项目</p>
<p>3.2 文 件 存 储 空 间 管 理：<br>– 辅存空间分配常采用以下两种办法。<br>– 连续分配：<br>• 文件被存放在辅存空间连续存储区中，在建立文件时，用户必须给出文件大小；<br>• 然后，查找到能满足的连续存储区供使用；否则文件不能建立。<br>– 连续分配的优点是文件查找速度快，管理较为简单，但为了获得足够大的连续存储区。需定时进行‘碎片’收集。因而，不适宜于文件频繁进行动态扩充和缩小的情况，用户事先不知道文件长度也无法进行分配。</p>
<p>非连续分配：<br>• 一种非连续分配方法是以块（或扇区）为单位，按文件动态要求分配给它若干扇区，这些扇区不一定要连续。<br>• 另一种非连续分配方法是以簇为单位，簇是由若干个连续扇区组成的分配单位；实质上是连续分配和非连续分配的结合。各个簇可以用链指针、索<br>引表，位示图来管理。非连续分配的优点是辅存空间管理效率高，访问文件执行速度快，特别是以簇为单位的分配方法已被广泛使用。</p>
<p>3.3 文件系统的使用<br>– 在文件系统中提供对文件的各种操作，形式分别为：系统调用或命令。</p>
<ol>
<li><p>主要操作<br>– 提供设置和修改对用户文件存取权限<br>– 提供建立、修改、改变、删除目录的服务<br>– 提供文件共享，设置访问路径的服务<br>– 提供创建、打开、读、写、关闭、撤消文件等服务<br>– 文件系统维护</p>
</li>
<li><p>操作介绍<br>（1）建立文件<br>实质是建立文件的FCB，并建立必要的存储空间，分配空FCB，根据提供的参数及需要填写有关内容，返回一个文件描述。<br>目的：建立系统与文件的联系<br>（2）打开文件<br>使用文件的第一步，任何一个文件使用前都要先打开，即把FCB送到内存</p>
</li>
</ol>
<p>3.4 文件系统的可靠性<br>– 可靠性：<br>• 系统抵抗和预防各种物理性破坏和人为性破坏的能力。<br>– 备份<br>• 通过转储操作，形成文件或文件系统的多个副本</p>
<p>3.5 磁盘冗余阵列 RAID<br>– RAID(Reundant Array of Independent Disks)<br>– 它是利用一台磁盘阵列控制器统一管理和控制一组磁盘驱动器。<br>– 其策略是:用一组较小容量的、独立的、可并行工作的磁盘驱动器组成阵列来代替单一的大容量磁盘，独立的I/O请求能被并行地从多个磁盘驱动器同时存取数据，从而，改进了I/O性能和系统可靠性</p>
<p>3.6 文 件 系 统 的 性 能<br>（1） 磁盘调度<br>当多个访盘请求在等待时，采用一定的策略，对这些请求的服务顺序调整安排，旨在降低平均磁盘服务时间，达到公平、高效<br>– 公平：一个I/O请求在有限时间内满足<br>– 高效：减少设备机械运动所带来的时间浪费</p>
<p>（2）磁盘调度考虑的问题：<br>一次访盘时间 = 寻道时间+旋转延迟时间+存取时间<br>– 减少寻道时间<br>– 减少延迟时间</p>
<p>（3）磁盘调度算法<br>1） 先来先服务：按访问请求到达的先后次序服务<br>例：假设磁盘访问序列：98，183，37，122，14，124，65，67，读写头起始位置：53，安排磁头服务序列，计算磁头移动总距离（道数）<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile6.png?raw=true" alt="Image text"><br>– 优点：简单，公平；<br>– 缺点：效率不高，相临两次请求可能会造成最内到<br>最外的柱面寻道，使磁头反复移动，增加了服务时间，<br>对机械也不利。</p>
<p>2）最 短 寻 道 时 间 优 先<br>– 最短寻道时间优先：优先选择距当前磁头最近的访问请求进行服务，主要考虑寻道优先<br>– 优点：改善了磁盘平均服务时间；<br>– 缺点：造成某些访问请求长期等待得不到服务</p>
<p>例：假设磁盘访问序列：98，183，37，122，14，124，65，67，读写头起始位置：53，安排磁头服务序列，计算磁头移动总距离（道数）<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile7.png?raw=true" alt="Image text"><br>– 采用最短寻道时间优先调度下的总移动道数：236<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile8.png?raw=true" alt="Image text"></p>
<p>3）电梯算法<br>克服了最短寻道优先的缺点，既考虑了距离，同时又考虑了方向。<br>– 当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方向，并为经过的访问请求服务，如此反复<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osfile9.png?raw=true" alt="Image text"></p>
<p>4）单 向 扫 描 调 度 算 法<br>– 总是从0号磁道开始向里扫描<br>– 按照各自所要访问的磁道位置的次序去选择访问者<br>– 移动臂到达最后个一个磁道后，立即带动读写磁头快速返回到0号磁道<br>– 返回时不为任何的等待访问者服务<br>– 返回后可再次进行扫描</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/29/OS文件管理/" data-id="cjuceyeyi0011fgs6x6lddn8q" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OS存储管理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/29/OS存储管理/" class="article-date">
  <time datetime="2019-03-29T03:31:30.832Z" itemprop="datePublished">2019-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/29/OS存储管理/">操作系统-存储管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、存 储 概 述<br>由于任何程序、数据必须占用主存空间后才能执行，因此存储管理直接影响系统的性能。</p>
<p>– 主存储空间一般分为两部分：<br>• 一部分是系统区，存放操作系统常驻内存部分；<br>• 另一部分是用户区，存放用户的程序和数据等</p>
<p>存储管理主要是对用户区域进行管理，当然也包括对辅存的管理。目的是要尽可能地方便用户使用和提高主存储器的效率</p>
<p>存储层次结构<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey1.png?raw=true" alt="Image text"></p>
<p>存储管理应具有的四大功能:<br>1 ） 内存空间管理<br>– 记录每个内存单元的使用情况<br>– 内存分配<br>– 位示图：用一位（bit）表示一个空闲页面（0：空闲，1：占用）</p>
<p>2）地址变换（重定位，地址映射）<br>我们把用户编程时使用的地址称为逻辑地址，把程序在内存中的实际地址称为物理地址。为了保证程序的正确运行，必须把程序和数据的逻<br>辑地址转换为物理地址，这一工作称为地址转换或重定位。</p>
<p>– 静态地址转换<br>• 当用户程序被装入内存时，一次性实现逻辑地址到物理地址的转换，以后不再转换。<br>• 一般在装入内存时由重定位装入程序完成。</p>
<p>– 动态地址转换<br>• 在程序运行过程中要访问数据时再进行地址变换（即在逐条指令执行时完成地址映射。一般为了提高效率，此工作由硬件地址映射机制来<br>完成。硬件支持，软硬件结合完成）。<br>• 一对寄存器（VR，BR）</p>
<p>静态重定位：<br>– 优点：无须硬件支持；<br>– 缺点：<br>（1）不支持虚拟存储，原因是执行期间程序不能移动，因而不能实现重新分配内存，而虚拟存储则将部分程序装入内存。<br>（2）不能共享。因为每个程序必须占用连续的内存空间，因此很难做到。</p>
<p>动态重定位：<br>– 过程：<br>（1）设置基址寄存器BR，虚拟地址寄存器VR<br>（2）将程序首址送入BR<br>（3）程序执行时，将需要访问的虚址送入VR<br>（4）将BR和VR相加，得到实际访问的地址。</p>
<p>– 优点：<br>（1）可以对内存进行非连续分配，对于不同程序段设置不同的BR即可。<br>（2）提供了实现虚拟存储的基础，动态重定位可以部分地、动态地分配内存。<br>（3）有利于共享。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey2.png?raw=true" alt="Image text"></p>
<p>3）内 存 扩 充<br>内存的容量是受实际的存储单元限制的，而运行的程序又不受内存大小的限制，这就需要有效的存储管理技术来实现内存的逻辑扩充，这种扩充不是增加实际的存储单元，而是通过虚拟存储技术、覆盖技术、交换技术等技术来实现的。</p>
<p>4）内存共享和保护<br>– 为了更有效地使用内存空间，要求共享内存<br>– 为多个程序共享内存提供保障，使在内存中的各道程序，只能访问它自己的区域，避免各道程序间相互干扰，特别是当一道程序发生错误时，不致于影响其他程序的运行<br>– 保护过程—-防止地址越界<br>– 保护过程—-防止操作越权</p>
<p>2、存储管理的一些技术<br>2.1 覆盖(overlay)<br>– 引入：其目标是在较小的可用内存中运行较大的程序。常用于多道程序系统，与分区存储管理配合使用<br>– 引入：其目标是在较小的可用内存中运行较大的程序。常用于多道程序系统，与分区存储管理配合使用<br>• 不存在调用关系的模块不必同时装入到内存，从而可以相互覆盖。(即不同时用的模块可共用一个分区)<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey3.png?raw=true" alt="Image text"></p>
<p>2.2 交换(swapping)<br>– 引入：多个程序并发执行，可以将暂时不能执行的程序送到外存中，从而获得空闲内存空间来装入新程序，或读入保存在外存中而目前到达就绪状态的进程。交换单位为整个进程的地址空间。<br>• 程序暂时不能执行的可能原因：处于阻塞状态，低优先级（确保高优先级程序执行）；</p>
<p>– 原理：暂停执行内存中的进程，将整个进程的地址空间保存到外存的交换区中（换出swa pout）而将外存中由阻塞变为就绪的进程的地址空间读<br>入到内存中，并将该进程送到就绪队列（换入swap in）。</p>
<p>– 优点：增加并发运行的程序数目，并且给用户提供适当的响应时间；编写程序时不影响程序结构，对用户透明。<br>– 缺点：对换入和换出的控制增加处理机开销；程序整个地址空间都进行传送，没有考虑执行过程中地址访问的统计特性。<br>– 覆盖技术和交换技术的发展导致了虚拟存储技术的出现</p>
<p>2.3 虚拟存储技术<br>虚存：把内存与外存有机的结合起来使用，从而得到一个容量很大的“内存”，这就是虚存<br>– 实现思想：当进程运行时，先将一部分程序装入内存，另一部分暂时留在外存，当要执行的指令不在内存时，由系统自动完成将它们从外存调入内存工作<br>– 目的：提高内存利用率</p>
<p>虚存的物质基础：<br>系统要有足够大的外存；<br>– 要有一定容量的内存来存放运行作业的部分程序<br>– 要有动态地址转换机构，实现逻辑地址转换；</p>
<p>特征：<br>– 虚拟性：指逻辑上扩大了内存容量，使用户看到的内存空间大于实际空间；<br>– 离散性：指内存在分配时采用的是离散分配的方式，目的是为了避免内存空间的浪费；<br>– 多次性：指一个作业不是全部一次性装入内存，而是在需要时装入部分；<br>– 交换性：指在一个进程运行期间，将暂不使用的程序和数据从内存调至外存，被调出的程序和数据在需要时再调入内存中。<br>– 总容量不超过物理内存和外存交换区容量之和</p>
<p>3、分区存储管理<br>– 把内存分为一些大小相等或不等的分区(partition)，每个应用进程占用一个分区。操作系统占用其中一个分区。<br>– 问题：可能存在内碎片和外碎片。<br>• 内碎片：占用分区之内未被利用的空间<br>• 外碎片：占用分区之间难以利用的空闲分区（通常是小空闲分区）。</p>
<p>3.1 固定分区(fixed partitioning)<br>– 把内存划分为若干个固定大小的连续分区。每个分区装一个且只能装一个作业。<br>• 分区大小相等：<br>• 分区大小不等：多个小分区、适量的中等分区、少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey4.png?raw=true" alt="Image text"><br>优点：易于实现，开销小。<br>– 缺点：<br>• 内碎片造成浪费<br>• 分区总数固定，限制了并发执行的程序数目。</p>
<p>3.2 动态分区(dynamic partitioning)<br>基本思想:<br>• 作业装入时，根据作业的需求和内存空间的使用情况来决定是否分配<br>• 若有足够的空间，则按需要分割一部分分区给该进程；否则令其等待内存空间</p>
<p><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey5.png?raw=true" alt="Image text"></p>
<p>– 分区分配算法：寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区的先后次序通常是从内存低端到高端。<br>– 分区释放算法：需要将相邻的空闲分区合并成一个空闲分区。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）最先适应法(first-fit)：按分区的先后次序，从头查找，找到符合要求的第一个分区</span><br><span class="line"><span class="number">2</span>）下次适应法(next-fit)：按分区的先后次序，从上次分配的分区起查找（到最后分区时再回到开头），找到符合要求的第一个分区</span><br><span class="line"><span class="number">3</span>）最佳适应法(best-fit)：找到其大小与要求相差最小的空闲分区</span><br><span class="line"><span class="number">4</span>）最坏适应法(worst-fit)：找到最大的空闲分区</span><br></pre></td></tr></table></figure></p>
<p>3.3 碎 片 问 题<br>– 紧凑技术：通过在内存移动程序，将所有小的空闲区域合并为大的空闲区域<br>(内存紧凑(compaction)：将各个占用分区向内存一端移动。使各个空闲分区聚集在另一端，然后将各个空闲分区合并成为一个空闲分区)</p>
<p>3.4 分区的回收及保护<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）该空闲区的上下相邻分区都是空闲区。将三个空闲区合并，合并后的起始地址为上空闲区的起始地址，修改可用表或自由链（取消下，修改上）</span><br><span class="line"><span class="number">2</span>）该空闲区的上相邻区是空闲区。与上相邻区合并，合并后的起始地址为上空闲区的起始地址，修改可用表或自由链（修改上的大小）。</span><br><span class="line"><span class="number">3</span>）该空闲区的下相邻区是空闲区。与下相邻区合并，合并后的起始地址为释放区的起始地址，修改可用表或自由链（修改下的始址和大小）。</span><br><span class="line"><span class="number">4</span>）该空闲区不与其他空闲区相邻,作为一个新空闲区插入可用表或自由链</span><br></pre></td></tr></table></figure></p>
<p>4、页式存储管理<br>4.1 基本思想:<br>– 用户程序划分<br>• 把用户程序按逻辑页划分成大小相等的部分，称为页。从0开始编制页号，页内地址是相对于0编址<br>– 逻辑地址<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey6.png?raw=true" alt="Image text"><br>内存空间<br>• 按页的大小划分为大小相等的区域，称为内存块（物理页面）<br>– 内存分配<br>• 以页为单位进行分配，并按作业的页数多少来分配。<br>• 逻辑上相邻的页，物理上不一定相邻</p>
<p><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey7.png?raw=true" alt="Image text"></p>
<p>4.2 管理<br>– 页表：系统为每个进程建立一个页表，页表给出逻辑页号和具体内存块号相应的关系<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey8.png?raw=true" alt="Image text"></p>
<p>地址映射机制：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey9.png?raw=true" alt="Image text"></p>
<p>地址映射机制（含快表）：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey10.png?raw=true" alt="Image text"></p>
<p>4.3 静态页式管理<br>– 将程序的逻辑地址空间和物理内存划分为固定大小的页或页面(Page or Page frame)，程序加载时，分配其所需的所有页，这些页不必连续<br>静态页式管理的地址变换：<br>– 指令所给出地址分为两部分：逻辑页号，页内偏移地址－&gt;查进程页表，得物理页号－&gt;物理地址</p>
<p>– 优点：<br>• 没有外碎片，每个内碎片不超过页大小（因为页面大小固定 要多少有多少）。<br>• 一个程序不必连续存放。<br>• 便于改变程序占用空间的大小。即随着程序运行<br>而动态生成的数据增多，地址空间可相应增长。<br>– 缺点：<br>• 程序全部装入内存，受到内存可用页面数的限制。</p>
<p>4.4 动态（请求）页式管理<br>– 在进程开始运行之前，不是装入全部页面，而是装入部分页面，之后根据进程运行的需要，动态装入其它页面；当内存空间已满，而又需要装入新的页面时，则根据某种算法淘汰某个页面，以便装入新的页面。</p>
<p>页表表项：<br>– 页号、驻留位、内存块号、外存始址、访问位、修改位<br>– 驻留位（中断位）：表示该页是在内存还是在外存<br>– 访问位：根据访问位来决定淘汰哪页（由不同的算法决定）<br>– 修改位：查看此页是否在内存中被修改过<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey11.png?raw=true" alt="Image text"></p>
<p>缺页中断处理：<br>在地址映射过程中，在页表中发现所要访问的页不在内存，则产生缺页中断。操作系统接到此中断信号后，就调出缺页中断处理程序，根据页表中给出的外存地址，将该页调入内存，使作业继续运行下去<br>– 如果内存中有空闲块，则分配一页，将新调入页装入内存，并修改页表中相应表项<br>– 若此时内存中没有空闲块，则要淘汰某页，若该页在内存期间被修改过，则要将其写回外存<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey12.png?raw=true" alt="Image text"></p>
<p>页面置换算法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">– 随机置换算法</span><br><span class="line">– 先进先出算法(FIFO)</span><br><span class="line">– 最近最久未使用算法(LRU, Least Recently Used)</span><br><span class="line">– 时钟页面替换算法(Clock Policy) </span><br><span class="line">– 最佳置换算法(OPT, optimal)</span><br></pre></td></tr></table></figure></p>
<p>1）先进先出算法( F I F O )<br>– 选择建立最早的页面被置换，性能较差，较早调入的页往往是经常被访问的页，这些页在FIFO算法下被反复调入和调出。<br>– 并且有Belady现象。<br>– Belady现象：采用FIFO算法时，如果对一个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多，缺页率反而提高的异常现象。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey13.png?raw=true" alt="Image text"></p>
<p>2）最近最久未使用算法( L R U )<br>– 该算法淘汰的页面是在最近一段时间里较久未被访问的那一页。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey14.png?raw=true" alt="Image text"></p>
<p>3）最佳算法(OPT, optimal)<br>– 选择“未来不再使用的”或“在离当前最远位置上出现的”页面被置换，这是一种理想情况。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey15.png?raw=true" alt="Image text"></p>
<p>影 响 缺 页 次 数 的 因 素：<br>(1) 分配给进程的物理页面数<br>(2) 页面本身的大小<br>(3) 程序的编制方法<br>(4) 页面淘汰算法</p>
<p>4.5 页式管理的优缺点<br>– 相对于分区管理而言，静态页式有效的解决了外部碎片的问题（当然有少量的内部碎片）；<br>– 但是，静态页式要求全部装入，不支持虚拟存储，因而有了请求（动态）页式，允许部分装入；<br>– 显然地，请求页式更能有效利用有限的内存页面，不过，这种方式需要有效解决缺页率的问题，尤其是页面置换的问题；</p>
<p>5、段式存储管理<br>5.1 基本原理<br>用户程序划分<br>•按程序自身的逻辑关系划分为若干个程序段，每个程序段都有一个段名，且有一个段号。段号从0开始，每一段也从0开始编址，段内地址是连续的</p>
<p>– 逻辑地址（二维地址）<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey16.png?raw=true" alt="Image text"></p>
<p>基本原理：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey17.png?raw=true" alt="Image text"></p>
<p>内存划分方式：<br>– 内存划分<br>内存空间被动态的划分为若干个长度不相同的区域，称为物理段，每个物理段由起始地址和长度确定<br>– 内存分配<br>以段为单位分配内存，每一个段在内存中占据连续空间（内存随机分割，需要多少分配多少），但各段之间可以不连续存放</p>
<p>段式管理：<br>(1) 段表：每进程一个<br>(2) 空闲表：系统一个（管理同动态分区）array of (addr,size)<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey18.png?raw=true" alt="Image text"></p>
<p>内存分配：<br>（1）有足够空闲区（同动态分区）<br>最先适应<br>最佳适应<br>最坏适应<br>（2）没有足够空闲区（同请求页式）<br>FIFO，LRU，如果淘汰一段不能满足要求，就要进行多次淘汰</p>
<p>地址映射：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey19.png?raw=true" alt="Image text"></p>
<p>页式管理与段式管理的比较：<br>– 分页是出于系统管理的需要，分段是出于用户应用的需要<br>– 页大小是系统固定的，而段大小则通常不固定。<br>– 逻辑地址表示：<br>• 分页是一维的，各个模块在链接时必须组织成同一个地址空间；<br>• 分段是二维的，各个模块在链接时可以每个段组织成一个地址空间。<br>– 通常段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度。</p>
<p>6、段页式存储管理<br>– 分段结构具有逻辑上清晰的优点，但它的一个致命弱点是每个段必须占据主存储器的连续区域，为了克服这个缺点，可兼用分段和分页的方法，构成段页式存储管理。<br>– 每个作业仍按逻辑分段，把每个段再分成若干个页面，每一段不必占据连续的主存空间，可把它按页存放在不连续的主存块中。</p>
<p>6.1  基 本 思 想<br>– 用户程序划分：按段式划分（对用户来讲，按段的逻辑关系进行划分；对系统讲，按页划分每一段）<br>内存划分：按页式存储管理方案<br>内存分配：以页为单位进行分配<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey20.png?raw=true" alt="Image text"></p>
<p>段 表 和 页 表：<br>（1）在段页式系统中,每个分段又被分成若干个固定大小的页面，那么每个段又必须建立一张页表把段中的虚页变换成内存中的实际页面。显然，与页式管理时相同，页表中也要有相应的实现缺页中断处理和页面保护等功能表项。<br>（2）每个段有一个页表，段表中应有专项指出该段所对应页表的页表始址和页表长度</p>
<p>段 表 、 页 表 与 内 存 关 系：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey21.png?raw=true" alt="Image text"></p>
<p>段页式地址变换：<br>注：在段页式系统中，为了获取一条指令或数据，需三次访问内存。<br>• 第一次访问，是访问内存中的段表，从中取得页表始址<br>• 第二次访问，是访问内存中的页表，从中取得物理块号，并将该块号与页内地址一起形成指令或数据的物理地址<br>• 第三次访问，才是真正从第二次访问的地址中，取得指令和数据</p>
<p>抖 动：<br>– 虚存中，页面在内存与外存之间频繁调度，以至于调度页面所需时间比进程实际运行的时间还多，此时系统效率急剧下降，甚至导致系统崩溃。这种现象称为颠簸或抖动<br>– 原因：<br>• 页面淘汰算法不合理<br>• 分配给进程的物理页面数</p>
<p>一点总结：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey22.png?raw=true" alt="Image text"><br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey23.png?raw=true" alt="Image text"><br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osmey24.png?raw=true" alt="Image text"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/29/OS存储管理/" data-id="cjuceyez10016fgs6i7bus37w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OS处理机管理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/28/OS处理机管理/" class="article-date">
  <time datetime="2019-03-28T09:56:31.303Z" itemprop="datePublished">2019-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/28/OS处理机管理/">操作系统-处理机管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、调度的性能准则:<br>– （平均）周转时间：作业从提交到完成的时间（用户角度）<br>周转时间：Ti=Tc-Ts<br>Tc作业完成时刻；<br>Ts作业进入系统时刻</p>
<p>平均周转时间：（T1+T2+…+Tn)/n</p>
<p>– （平均）带权周转时间：周转时间 / CPU运行时间（用户角度）<br>带权周转时间:<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi7.png?raw=true" alt="Image text"></p>
<p>平均带权周转时间：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi8.png?raw=true" alt="Image text"></p>
<p>– 吞吐量：单位时间内所完成的作业数<br>– 处理机利用率：CPU运行时间 / 总时间<br>– 各种设备的均衡利用：如CPU繁忙的作业和I/O繁忙的作业搭配</p>
<p>调度的类型:<br>– 作业：又称为”宏观调度”、”高级调度”。从用户工作流程的角度，一次提交的若干个流程。<br>– 内外存交换：又称为”中级调度”。从存储器资源的角度。将进程的部分或全部换出到外存上，将当前所需部分换入到内存。指令和数据必须在内存里才能被CPU直接访问。<br>– 进程：又称为”微观调度”<br>、<br>“低级调度”。从CPU资源<br>的角度，执行的单位。时间上通常是毫秒。因为执行频<br>繁，要求在实现时达到高效率</p>
<p>2、处理机调度算法<br>2.1 先 来 先 服 务（非抢占方式）<br>按先后顺序进行调度</p>
<p>2.2 短 作 业 优 先（非抢占方式）<br>又称为“短进程优先”SPN(Shortest Process<br>Next)；这是对FCFS算法的改进，其目标是减少平均周<br>转时间</p>
<p>– 优点：<br>• 比FCFS改善平均周转时间和平均带权周转时间，缩短作业<br>的等待时间；<br>• 提高系统的吞吐量；<br>– 缺点：<br>• 对长作业非常不利，可能长时间得不到执行；<br>• 未能依据作业的紧迫程度来划分执行的优先级；<br>• 难以准确估计作业（进程）的执行时间，从而影响调度性<br>能</p>
<p>2.3 最短剩余时间优先（抢占式）<br>允许比当前进程剩余时间更短的进程来抢占</p>
<p>2.4 最高响应比优先（非抢占方式）<br>• 响应比R = (等待时间 + 要求执行时间) / 要求执行时间<br>• 是FCFS和SJF的折衷</p>
<p>2.5 时间片轮转(Round Robin)算法<br>本算法主要用于微观调度，说明怎样并发运行，即切换的方式；设计目标是提高资源利用率。<br>其基本思路是通过时间片轮转，提高进程并发性和响应时间特性，从而提高资源利用率；</p>
<p>2.6 多级队列算法(Multiple-level Queue)<br>各队列的不同处理：不同队列可有不同的优先级、时间片长度、调度策略等</p>
<p>2.7 优先级算法(Priority Scheduling)（可分成抢先式和非抢先式）<br>1）静态优先级<br>– 创建进程时就确定，直到进程终止前都不改变。通常是一个整数</p>
<p>2）动态优先级<br>在就绪队列中，等待时间延长则优先级提高，从而使优先级较低的进程在等待足够的时间后，其优先级提高到可被调度执行；<br>– 进程每执行一个时间片，就降低其优先级，从而一个进程持续执行时，其优先级降低到出让CPU</p>
<p>注意：<br>I/O型进程：让其进入最高优先级队列，以及时响应I/O交互。通常执行一个小时间片，要求可处理完一次I/O请求的数据，然后转入到阻塞队列。<br>– 计算型进程：每次都执行完时间片，进入更低级队列。最终采用最大时间片来执行，减少调度次数。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/28/OS处理机管理/" data-id="cjuceyeww0003fgs6us64scmr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OS进程管理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/28/OS进程管理/" class="article-date">
  <time datetime="2019-03-28T08:35:47.114Z" itemprop="datePublished">2019-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/28/OS进程管理/">操作系统-进程管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、程序<br>1.1 顺序程序<br>我们把一个具有独立功能的程序独占处理机直至最终结束的过程称为程序的顺序执行</p>
<p>特征：<br>– 顺序性：各条指令按照严格的顺序执行。<br>– 封闭性：程序执行得到的最终结果由给定的初始条<br>件决定，独占资源，不受外界影响。<br>– 可再现性：初始条件相同，则重复执行的结果相同<br>（与执行速度无关）。</p>
<p> 1.2 并发程序<br> – 并发的目的：增强处理能力，提高资源利用率。<br>– 并发的含义：在一定时间内有多个程序同时处于运<br>行但尚未结束的状态，并且次序事先确定的</p>
<p>特征：<br>– 间断(异步)性：由于并发程序之间的制约，导致<br>“走走停停”，一个程序可能走到中途停下来；<br>– 失去封闭性：共享资源，受其他程序的影响。如：<br>一个程序写到存储器中的数据可能被另一个程序修改，<br>失去原有的不变特征。<br>– 失去可再现性：失去封闭性 －&gt;失去可再现性；外<br>界环境在程序的两次执行期间发生变化，失去原有的可<br>重复特征。</p>
<p>2、进 程<br>2.1 定义：Process<br>程序在执行过程中分配和管理资源的基本单位<br>（这里的程序指的是一组操作序列，具有动态特性）。</p>
<p>2.2 程序与进程之间的区别：<br>– 程序是静态的，进程是动态的，强调执行过程<br>– 进程具有并行特征，即不考虑资源共享的情况下，<br>各个进程的执行是独立的，执行速度是异步的。而程序<br>不反映执行过程，不具有并行特征<br>– 进程是竞争系统资源的基本单位<br>– 不同的进程可以包含同一程序，只要对应的数据集<br>不同</p>
<p>2.3 进程的特征<br>（1）并发性。可以同其他进程一道向前推进。<br>（2）动态性。进程是程序的执行过程，动态产生，<br>动态消亡，状态变换。<br>（3）独立性。一个进程是一个相对完整的资源分配<br>单位。<br>（4）交往性。进程之间的相互作用。<br>（5）异步性。各个进程按照各自独立的、不可预知<br>的速度向前推进。</p>
<p>2.4 进 程 的 描 述<br>进程的静态描述由三部分组成：PCB，程序段，数据<br>集。<br>• PCB是系统感知进程的唯一实体；<br>• 程序描述进程所需要完成的功能；<br>• 而数据集是程序执行的对象</p>
<p>2.5 进程控制块(Process Control Block)<br>– 系统为了管理进程设置的一个专门的数据结构，用<br>它来记录进程的外部特征，描述进程的运动变化过程<br>– 系统利用PCB来控制和管理进程，所以PCB是系统感<br>知进程存在的唯一标志<br>– 进程与PCB是一一对应的</p>
<p>2.6 进 程 状 态 及 其 转 换<br>– 运行态（Running）：<br>进程占有CPU，并在CPU上运行<br>– 就绪态（Ready）：<br>一个进程已经具备运行条件，但由于无CPU暂<br>时不能运行的状态（当调度给其CPU时，立即可以<br>运行）<br>– 等待态（Waiting/Blocked）：<br>指进程因等待某种事件的发生而暂时不能运行<br>的状态（即使CPU空闲，该进程也不可运行）</p>
<p>1）三状态图：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro1.png?raw=true" alt="Image text"></p>
<p>2）五状态图：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro2.png?raw=true" alt="Image text"></p>
<p>3）七状态图：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro3.png?raw=true" alt="Image text"></p>
<p>3、线 程<br>进程：资源分配单位（存储器、文件）和CPU调度（分派）单位。<br>又称为”任务(task) “</p>
<p>线程：作为CPU调度单位，而进程作为其他资源分配单位。一个进<br>程内的基本调度单位。（轻权进程）</p>
<p>–线程：有时称轻量级进程<br>• 进程中的一个运行实体<br>• 是一个CPU调度单位<br>• 只拥有必不可少的资源，如：线程状态、寄存器上下文和栈<br>• 同样具有就绪、阻塞和执行三种基本状态</p>
<p>线程的优点：减小并发执行的时间和空间开销（线程的创建、退<br>出和调度），因此容许在系统中建立更多的线程来提高并发程度（进<br>程间的并发到进程内的并发）。提高系统执行效率，减少处理机空转<br>时间。<br>• 线程的创建时间比进程短；<br>• 线程的终止时间比进程短；<br>• 同进程内的线程切换时间比进程短；<br>• 由于同进程内线程间共享内存和文件资源，可直接进行不通过<br>内核的通信</p>
<p>4、进程与线程比较<br>– 进程：<br>• 资源分配的基本单位（PCB）；<br>• 抢占处理机的调度单位；<br>• 完整的虚拟地址空间；<br>• 由正文集，数据集和PCB组成；<br>• 进程切换时，涉及到有关资源信息的保存和地址空间的变化<br>• 进程调度与切换：操作系统内核完成；<br>– 线程：<br>• 与资源分配无关，与所属进程内的其他线程共享进程资源；<br>• 与所属进程内的其他线程共享同一地址空间；<br>• 由相关堆栈（系统栈或用户栈）寄存器和TCB组成，寄存器用来存放<br>存储在线程内的局部量；<br>• 线程切换时，不涉及到资源信息的保存和地址空间的变化，减少系统<br>的开销；<br>• 线程调度与切换：既可由操作系统内核完成，也可由用户程序进行；</p>
<p>线 程 的 分 类：<br>– 基本类型<br>• 用户级线程<br>• 系统级线程（核心级、内核级</p>
<p>4、进 程 控 制<br>– 所谓进程控制，就是系统使用一些具有特定功能的程序段来创建、撤销进程以及完成进程各状态间的转换，从而达到多进程高效率并发执行和协调，实现资源共享的目的。</p>
<p>– 原语：把系统下执行的某些具有特定功能的程序段称为原语，原语是不能被中断的。用于进程控制的原语有创建原语、撤销原语、阻塞原语、唤醒原语等等。</p>
<p>– 临界区：把系统中不允许同时多个进程访问的资源称为临界资源，而在进程中访问临界资源的那段程序称为临界区<br>注意：临界区不是资源，而是程序段</p>
<p>– 互斥：把不允许两个以上的共享某公有资源的并发进程同时进入临界区称为互斥<br>互斥的原则：<br>（1）空闲让进<br>（2）忙则等待<br>（3）有限等待<br>（4）让权等待</p>
<p>5、信 号量 和 P,V原 语<br>信号量（Semaphore）：信号量是一种特殊的变量，它的表面形式是一个整数附加一个队列。<br>信号量用于管理临界区的公有资源，信号量sem是一个整数<br>• sem大于等于0时代表可供并发进程使用的资源实体数<br>• sem小于0时则表示正在等待使用临界区的进程数。</p>
<p>P 原 语：(堵塞条件：s.value &lt; 0)<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">semaphore s;</span><br><span class="line">P(s)</span><br><span class="line">&#123;</span><br><span class="line">封锁中断；<span class="comment">//该原语执行过程中不允许中断</span></span><br><span class="line">s.value = s.value – <span class="number">1</span>；</span><br><span class="line"><span class="keyword">if</span> (s.value &lt; <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">保护当前进程CPU现场；</span><br><span class="line">该进程状态置为等待状态；</span><br><span class="line">将该进程的PCB插入相应的等待队列末尾s.queue；</span><br><span class="line">转进程调度；</span><br><span class="line">&#125;</span><br><span class="line">开中断；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>V 原 语:(唤醒条件：s.value &lt;= 0)<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">semaphore s;</span><br><span class="line">V(s)</span><br><span class="line">&#123;</span><br><span class="line">封锁中断；</span><br><span class="line">s.value = s.value + <span class="number">1</span>；</span><br><span class="line"><span class="keyword">if</span> (s.value &lt; = <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">唤醒相应等待队列s.queue中的一个等待进程；</span><br><span class="line">改变其状态为就绪态；</span><br><span class="line">并将其插入就绪队列；</span><br><span class="line">转进程调度；</span><br><span class="line">&#125;</span><br><span class="line">开中断；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>6、进 程 同 步<br>进程同步：把一组并发进程，因直接制约而相互发送消息进行互相合作，互相等待，使得各进程按一定的速度执行的过程称为进程间的同步<br>私 用 信 号 量：一般来说，也可以把各进程之间发送的消息作为信号量看待。与进程互斥时不同的是，这里的信号量只与制约进程及被制约进程有关，而不是与整组并发进程有关。因此，该信号量为私用信号量。<br>互斥时使用的信号量为公用信号量，同步时使用的信号量为私用信号量。</p>
<p>举例：司 机 — 售 票 员 问 题<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro4.png?raw=true" alt="Image text"><br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro5.png?raw=true" alt="Image text"></p>
<p>7、管 程<br>定义：指关于共享资源的数据及在其上操作的一组过程或共享数据结构及其规定的所有操作</p>
<p>管程有如下几个要素：<br>（一）管程中的共享变量在管程外部是不可见的，外部只能通过调用管程中所说明的外部过程（函数）来间接地访问管程中的共享变量<br>（二）为了保证管程共享变量的数据完整性，规定管程互斥进入<br>（三）管程通常是用来管理资源的，因而在管程中应当设有进程等待队列以及相应的等待及唤醒操作</p>
<p>8、进 程 通 信<br>进程通信：进程之间互相交换信息的工作称之为进程通信IPC(InterProcess Communication)。<br>8.1 进程间通信的类型<br>– 低级通信：只能传递状态和整数值（控制信息），包括进程互斥和同步所采用的信号量机制。<br>– 高级通信：能够传送任意数量的数据，包括三类：共享存储区、管道、消息。<br>– 直接通信：信息直接传递给接收方，如管道。<br>间接通信：借助于收发双方进程之外的共享数据结构作为通信中转，如消息队列。</p>
<p>8.2 共享存储区通信机制<br>内存中开辟一个共享存储区，诸进程通过该区实现通信,这是进程通信中最快的方法。</p>
<p>8.3 管 道 通 信 机 制<br>管道(pipe)是连接读写进程的一个特殊文件，允许进程按先进先出方式传送数据。发送进程以字符流形式<br>把大量数据送入管道，接收进程从管道中接收数据，所以，也叫管道通信<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro6.png?raw=true" alt="Image text"></p>
<p>8.4 消息传递机制<br>1）直接通信方式<br>在直接通信方式下，企图发送或接收消息的每个进程必须指出信件发给谁或从谁那里接收消息，可用send原语和receive原语为实现进程之间的通信<br>2）间接通信方式<br>采用间接通信方式时，进程间发送或接收消息通过一个信箱来进行，消息可以被理解成信件，每个信箱有一个唯一的标识符。</p>
<p>9、死锁<br>现象：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro7.png?raw=true" alt="Image text"></p>
<p>定义：一组进程中，每个进程都无限等待被该组进程中另一进程所占有的资源，因而永远无法得到资源，这种现象称为进程死锁，这一组进程就称为死锁进程<br>– 参与死锁的进程最少是两个（两个以上进程才会出现死锁）<br>– 参与死锁的进程至少有两个已经占有资源<br>– 参与死锁的所有进程都在等待资源<br>– 参与死锁的进程是当前系统中所有进程的子集</p>
<p>资源：<br>– 永久性资源：可以被多个进程多次使用（可重用资<br>源）<br>• 可抢占资源<br>• 不可抢占资源<br>– 临时性资源：只可使用一次的资源；如信号量,中断<br>信号，同步信号等（可消耗性资源）<br>• “申请–分配–使用–释放”模式</p>
<p>例 子：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro8.png?raw=true" alt="Image text"><br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro9.png?raw=true" alt="Image text"></p>
<p>10、产生死锁的四个必要条件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">互斥使用（资源独占）</span><br><span class="line">不可强占（不可剥夺）</span><br><span class="line">请求和保持（部分分配，占有已分配）</span><br><span class="line">循环等待（环路等待）</span><br></pre></td></tr></table></figure></p>
<p>解决死锁的方法:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>) 不考虑此问题（鸵鸟政策）</span><br><span class="line"><span class="number">2</span>) 预防死锁（破坏死锁条件）</span><br><span class="line"><span class="number">3</span>) 避免死锁（分配过程中采用策略）</span><br><span class="line"><span class="number">4</span>) 检测死锁（允许发生死锁）</span><br><span class="line"><span class="number">5</span>) 解除死锁（与检测死锁配套）</span><br></pre></td></tr></table></figure></p>
<p>1）鸵鸟政策<br>最简单的方法是象鸵鸟一样对死锁视而不见。</p>
<p>2) 死锁预防（破坏死锁条件）<br>在系统设计时确定资源分配算法，限制进程对资源的申请，从而保证不发生死锁。<br>具体的办法是破坏产生死锁的必要条件：<br>（1）破坏“不可剥夺”条件<br>一个进程在申请新资源的要求不能立即得到满足时，便处于等待状态。而一个处于等待状态的进程的全部资源可以被剥夺。该进程重新获得它原有的资源以及得到新申请的资源时，才能重新启动执行。</p>
<p>（2）破坏“请求和保持”条件<br>方法一：采用静态分配策略<br>每个进程在开始执行前就申请他所需要的所有资源，只有当系统能够把资源一次性分配，该进程才能执行。<br>缺点：资源浪费严重。<br>方法二：<br>如果进程已经占用资源同时再去申请资源，则它应该首先释放已占有的资源再重新申请新资源</p>
<p>（3）破坏“循环等待”条件<br>采用资源有序分配法：<br>把系统中所有资源编号，进程在申请资源时必须严格按资源编号的递增次序进行，否则操作系统不予分配；释放资源时，应按编号递减次序进行。</p>
<p>3) 死锁避免（分配过程中采用策略）<br>在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配</p>
<p>与死锁预防的区别：<br>死锁预防是设法破坏产生死锁的必要条件，严格防止死锁的发生。而死锁避免则没有这么严格，它是一种动态策略</p>
<p>安全状态：<br>如果存在一个由系统中所有进程构成的安全序列P1，„Pn，则系统处于安全状态。<br>一个进程序列{P1，„，Pn}是安全的，如果对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j &lt; i )当前占有资源量之和，系统处于安全状态，不会发生死锁。</p>
<p>不安全状态:<br>不存在一个安全序列，不安全状态不一定导致死锁</p>
<p>银行家算法：<br>银行家算法的基本思想是：<br>在安全状态下系统收到一个进程的资源请求后,先把资源试探性分配给它。在进程集合中找到剩余资源能满足最大需求量的进程,从而保证这个进程运行完毕并归还全部资源。这时,把这个进程从集合中去掉, 系统的剩余资源更多了,再反复执行上述步骤。<br>最后,检查进程集合,若为空表明本次申请可行,系统处于安全状态,可真正实施本次分配;否则,有进程执行不完，系统处于不安全状态,本次资源分配暂不实施,让申请进程等待。</p>
<p>银行家例子：第一次分配后的系统状态<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro10.png?raw=true" alt="Image text"><br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro11.png?raw=true" alt="Image text"></p>
<p>新 的 系 统 状 态：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro12.png?raw=true" alt="Image text"></p>
<p>4）死锁检测<br>允许死锁发生，操作系统不断监视系统进展情况，判断死锁是否发生。<br>最常用的检测死锁的方法就是对资源分配图进行化简。<br>①在图中找一个请求边均能立即满足的一个进程顶点Pi；<br>②若找到了这样的Pi，则将与Pi相连的边全部删去，转①</p>
<p>如果化简后所有的进程顶点都成了孤立点，则称该图可完全化简，否则不可完全化简(是产生死锁的充分必要条件，非孤立点的进程处于死锁状态。</p>
<p>5）死锁解除<br>一般通过破坏循环等待条件<br>从死锁进程集合中选择一个或多个进程予以删除，并剥夺它们的资源给其它的进程使用。选择要删除的进程时，一般从优先级、已运行时间及已用多少资源等几个方面去考虑，使系统损失最小</p>
<p>6）死锁的综合处理<br>一般来说，无论哪种方法都无法适用于每类资源，可以把系统中的全部资源分成几大类，整体上采用有序资源分配法，再对每类资源根据其特点选择最合适的方法。<br>例如，系统中有以下几类资源：<br>①主存；<br>②作业资源(打印机、磁带驱动器、文件等)；<br>③辅存。<br>将①②③类资源编号为1、2、3，按有序资源申请。对第①类<br>采用剥夺法；<br>对第②类采用死锁避免法；<br>对第③类采用静态资源分配法；</p>
<p>11、资 源 分 配 图<br>资源类（资源的不同类型）<br>-用方框表示<br>资源实例（存在于每个资源中）<br>-用方框中的黑圆点表示<br>进程<br>-用圆圈中加进程名表示<br>分配边：<br>资源实例→进程的一条有向边<br>申请边：<br>进程→资源类的一条有向边</p>
<p>11.1 有环有死锁<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro13.png?raw=true" alt="Image text"></p>
<p>11.2 有环无死锁<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ospro14.png?raw=true" alt="Image text"></p>
<p>11.3 死锁定理<br>如果资源分配图中没有环路，则系统中没有死锁，如果图中存在环路则系统中可能存在死锁<br>如果每个资源类中只包含一个资源实例，则环路是死锁存在的充分必要条件</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/28/OS进程管理/" data-id="cjuceyez10017fgs6vjt1m74c" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OS用户接口与作业调度" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/28/OS用户接口与作业调度/" class="article-date">
  <time datetime="2019-03-28T07:34:47.117Z" itemprop="datePublished">2019-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/28/OS用户接口与作业调度/">操作系统-用户接口与作业调度</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、程 序 的 启 动 和 结 束<br>1.1．程序的启动<br>– 程序开始执行时必须满足两个前提条件：<br>• 程序已装入内存<br>• 程序计数器PC中已置入该程序在内存的入口地址 </p>
<p>1.2 五种启动程序执行的方式<br>1）命令方式<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi1.png?raw=true" alt="Image text"></p>
<p>2）批处理方式<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi2.png?raw=true" alt="Image text"></p>
<p>3）EXEC方式<br>– 在一个程序中运行另一个程序<br>– 返回原来的程序<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi3.png?raw=true" alt="Image text"></p>
<p>4）由硬件装入程序和启动程序执行</p>
<p>5）自启程序<br>• 自己装入自己，并启动自己开始执行的程序<br>• 自启程序由两部分组成：引导程序和程序主体<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi4.png?raw=true" alt="Image text"></p>
<p>2、程序的结束<br>正常结束：程序按自身的逻辑有效地完成预定功能<br>后结束<br>（a）返回父程序并回送结果信息。<br>（b）释放所用资源（空间、设备），记录使用情<br>况，记帐等<br>– 异常结束：发生了某些错误而导致程序在没有完成<br>预定功能时提前结束 </p>
<p>3、用户与操作系统的接口<br>为用户提供两种接口：<br>（1）命令接口<br>用户通过这些命令来组织和控制作业的执行。<br>（2）程序接口<br>编程人员使用他们来请求操作系统服务。</p>
<p>作业控制的主要方式：<br>（1）联机命令接口<br>又称交互式命令接口，由一组键盘操作命令组<br>成。用户通过控制台或者终端键入操作命令，完<br>成对作业的控制。<br>（2）脱机命令接口<br>又称批处理命令接口，由一组作业控制语言组<br>成，由系统负责解释执行。（涉及到作业的相关<br>概念） </p>
<p>3、作 业 的 基 本 概 念<br>（1）作业<br>用户在一次计算过程中，或者一次事务处理过程中，<br>要求计算机系统所做工作的总称<br>（2）作业步<br> 一个作业可划分成若干部分，称为一个作业步<br>（3）典型的作业控制过程：<br> “编译”、“连接装配”、“运行” </p>
<p> 作业组织：<br> 作业由三部分组成，即程序、数据、作业说明书。</p>
<p> 作 业 控 制 块（JCB：Job Control Block）<br>– 作业控制块是作业存在的标志<br>– 保存现有系统对于作业进行管理所需要的全部信息<br>– 位于磁盘区域中 </p>
<p><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi5.png?raw=true" alt="Image text"></p>
<p>作 业 的 状 态 及 转 换：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi6.png?raw=true" alt="Image text"></p>
<p>4、作 业 调 度<br>调度的实质<br>• 资源的分配<br>– 调度算法定义<br>• 根据系统的资源分配策略所规定的资源分配算法</p>
<p>调 度 算 法 的 性 能 准 则：<br>– （平均）周转时间：作业从提交到完成的时间（用户角度）<br>周转时间：Ti=Tc-Ts<br>Tc作业完成时刻；<br>Ts作业进入系统时刻</p>
<p>平均周转时间：（T1+T2+…+Tn)/n</p>
<p>– （平均）带权周转时间：周转时间 / CPU运行时间（用户角度）<br>带权周转时间:<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi7.png?raw=true" alt="Image text"></p>
<p>平均带权周转时间：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi8.png?raw=true" alt="Image text"></p>
<p>– 响应时间：用户输入一个请求（如击键）到系统给出首次响应（如屏幕<br>显示）的时间（处理机的角度）<br>– 公平性：不因作业或进程本身的特性而使上述指标过分恶化（算法本身的角度）<br>– 优先级：可以使关键任务达到更好的指标（算法本身的角度）</p>
<p>5、先来先服务算法FCFS （First Come First Served）<br>– 按作业的先后顺序进行调度<br>– 处理过程<br>1）按照作业提交先后次序，分配CPU执行；<br>2）当前作业占用CPU，直到执行完或阻塞（如申请I/O）让出CPU；<br>3）作业被唤醒后（如I/O完成），不立即恢复执行，等待当前作业<br> 让出CPU后才可以恢复执行。<br>– 最简单的调度算法<br>– 对短作业不利（平均周转时间延长）</p>
<p>举例：假设在单道批处理环境下有四个作业，已知它们进入系统的时间、估计运行时间 ，求：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi9.png?raw=true" alt="Image text"></p>
<p>6、短 作 业 优 先 算 法 SJF （Shortest Job First ）<br>按作业的长短顺序进行调度，短作业优先<br>• 对预计执行时间短的作业优先分配CPU<br>• 通常后来的短作业不抢占正在执行的作业<br>– 对FCFS算法的改进，目标是减少平均周转时间</p>
<p>– 优点：<br>• 相比于FCFS改善平均周转时间和平均带权周转时间；<br>• 缩短作业的等待时间；<br>• 提高系统的吞吐量；<br>– 缺点：<br>• 对长作业非常不利，可能长时间得不到执行；<br>• 难以准确估计作业（进程）的执行时间，从而影响调度性能。<br>• 未能依据作业的紧迫程度来划分执行的优先级；</p>
<p>举例：<br>假设在单道批处理环境下有四个作业，已知它们进入系统的时间、估计运行时间 ，求：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi10.png?raw=true" alt="Image text"></p>
<p>7、最 短 剩 余 时 间 优 先 算 法 SRT （Shortest Remaining Time）<br>– 短作业优先算法的变型，也称作抢占式的短作业优先算法<br>– 允许比当前进程剩余时间更短的进程来抢占<br>– 抢占时机：新作业加入队列时 </p>
<p>8、最 高 响 应 比 优 先 算 法HRRN （Highest Response Ratio Next）<br>– 从就绪队列中选出响应比最高的作业投入执行<br>– 响应比R = (等待时间W +要求执行时间T) / 要求执行时间T<br>– FCFS和SJF的折衷</p>
<p>– 优点：既照顾了短作业，也考虑到先后顺序<br>– 缺点：每次调度时要调用响应比计算，增加了系统开销 </p>
<p>举例：假设在单道批处理环境下有四个作业，已知它们进入系统的时间、估计运行时间 ，求：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi11.png?raw=true" alt="Image text"></p>
<p>9、基 于 优 先 数 调 度 算 法 HPF （ Highest Priority First ）<br>（a）由用户规定优先数（外部优先数）<br> 用户提交作业时，根据急迫程度规定适当的优先数<br> 作业调度程序根据JCB优先数决定进入内存的次序<br>（b）由系统计算优先数（内部优先数） </p>
<p>举例：<br>在两道环境下有四个作业，已知它们进入系统的时间、估计运行时间； 作业调度采用短作业优先调度算法（作业被调度<br>运行后直到结束前不再退出内存）； 进程调度采用最短剩余时间优先调度算法（当新作业投入运行后，可按照作业剩余运行时间长短调整次<br>序，可抢占CPU）； 请给出这四个作业的执行时间序列，并计算出平均周转时间及平均带权周转时间；<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/osapi12.png?raw=true" alt="Image text"></p>
<p>10、系 统 调 用<br>系统调用，是用户在程序中调用操作系统所提供的一些子功能（程序接口）。<br>这个指令还将系统转入管态<br>系统调用是操作系统提供给编程人员的唯一接口 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/28/OS用户接口与作业调度/" data-id="cjuceyewy0004fgs6u9x1fw9l" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-os的硬件环境" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/28/os的硬件环境/" class="article-date">
  <time datetime="2019-03-28T03:18:16.509Z" itemprop="datePublished">2019-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/28/os的硬件环境/">操作系统的硬件环境</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、中央处理器（CPU）<br>构成:处理器由运算器、控制器、一系列的寄存器以及<br>高速缓存构成<br>– 运算器：实现指令中的算术和逻辑运算<br>– 控制器：负责控制程序运行的流程<br>– 寄存器：具有最快的访问速度<br>– 高速缓存：处于CPU和物理内存之间，访问速度快<br>于内存，低于寄存器</p>
<p>两类寄存器:<br>（1）用户编程寄存器<br>—数据寄存器<br>—地址寄存器<br>—条件码寄存器 </p>
<p>（2）控制状态寄存器<br>—程序计数器PC<br>—指令寄存器IR<br>—程序状态字PSW<br>—中断现场保护寄存器</p>
<p>处理器的状态:<br>– 管态：操作系统管理程序运行的状态，<br>较高的特权级别，又称为特权态（特态）、<br>系统态<br>– 目态：用户程序运行时的状态，较低的<br>特权级别，又称为普通态（普态）、用户态<br>– 特权指令：只能由操作系统使用的指令</p>
<p>管态和目态的差别:<br>– 处理器处于管态时：<br>• 全部指令（包括特权指令）可以执行<br>• 可使用所有资源<br>• 并具有改变处理器状态的能力<br>– 处理器处于目态时：<br>• 只有非特权指令能执行</p>
<p>CPU 状 态 的 转 换:<br>目态——–管态<br>其转换的唯一途径就是通过中断</p>
<p>管态——–目态<br>可用设置PSW实现</p>
<p>2、程 序 状 态 字 P S W<br>特殊寄存器，用以表明处理器当前的工作状态。</p>
<p>通常包括以下状态码：<br>（1）CPU的工作状态码——指明管态还是目态<br>（2）条件码——反映指令执行后的结果特征<br>（3）中断屏蔽码——指出是否允许中断</p>
<p>3、存储系统<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ophard1.png?raw=true" alt="Image text"></p>
<p>存 储 访 问 局 部 性 原 理:<br>提高存储系统效能关键点：程序存储访问局部性原理,处理器主要和存储器的局部打交道</p>
<p>4、中 断 机 制<br>中断机制是操作系统得以正常工作的最重<br>要的手段：<br>–它使得OS可以捕获普通程序发出的系统功能调用<br>–及时处理设备的中断请求<br>–防止用户程序中破坏性的活动等等</p>
<p>中 断：– CPU对系统发生的某个事件作出的一种反应<br>– CPU暂停正在执行的程序，保留现场后自动转去执行<br>相应事件的处理程序，处理完成后返回断点，继续执行<br>被打断的程序</p>
<p><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ophard2.png?raw=true" alt="Image text"></p>
<p>– 引入中断的目的<br>• 解决主机与外设的并行工作问题<br>• 提高可靠性<br>• 实现实时控制<br>– 特点：<br>• 中断是随机的<br>• 中断是可恢复的<br>• 中断是自动处理的</p>
<p>中 断 的 有 关 概 念：<br>– 中断源：引起中断发生的事件<br>– 中断寄存器：记录中断<br>– 中断字：中断寄存器的内容<br>– 系统堆栈:<br>在内存开辟的一块区域，用于临时保存现场</p>
<p>中断类型:<br>– 强迫性中断<br>• 正在运行的程序所不期望的，由于某种硬件故障<br>或外部请求引起的<br>– 自愿性中断<br>• 用户在程序中有意识安排的中断，是由于用户在<br>编制程序时因为要求操作系统提供服务，有意使用<br>“访管”指令或系统调用，使中断发生</p>
<p>强迫性中断<br>• 输入/输出(I/O)中断：主要来自外部设备通道<br>• 程序性中断：运行程序中本身的中断<br>(如溢出,缺页中断,缺段中断,地址越界)<br>• 时钟中断<br>• 硬件故障</p>
<p>自愿性中断<br>• 执行I/O，创建进程，分配内存<br>• 信号量操作，发送/接收消息<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/ophard3.png?raw=true" alt="Image text"></p>
<p>5、缓 冲 技 术<br>缓冲区是硬件设备之间进行数据传输时，<br>用来暂存数据的一个存储区域</p>
<p>–缓冲技术三种用途:<br>• 处理器与主存储器之间<br>• 处理器和其它外部设备之间<br>• 设备与设备之间的通信</p>
<p>–目的：解决部件之间速度不匹配的问题、使得部件并<br>行工作</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/28/os的硬件环境/" data-id="cjuceyex50009fgs6wnajfc8w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-操作系统概述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/27/操作系统概述/" class="article-date">
  <time datetime="2019-03-27T12:35:30.855Z" itemprop="datePublished">2019-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/27/操作系统概述/">操作系统概述</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、计算机系统的组成<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/op1.png?raw=true" alt="Image text"></p>
<p>操作系统的地位：<br>紧贴系统硬件之上，所有其他软件之下<br>（是其他软件的共同环境）<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/op2.png?raw=true" alt="Image text"></p>
<p>2、操作系统的作用:<br>(1)OS是计算机硬件、软件资源的管理者<br>管理的对象：CPU、存储器、外部设备、信息（数<br>据和软件）；<br>– 管理的内容：<br>1、资源的当前状态（数量和使用情况）<br>2、资源的分配、回收和访问操作<br>3、相应管理策略（包括用户权限）</p>
<p>(2)OS是用户使用系统硬件、软件的接口。<br>系统命令（命令行、菜单式、命令脚本式）；<br>– 系统调用（形式上类似于过程调用，在应用编程<br>中使用API）；<br>– 图形用户接口GUI</p>
<p>（3）OS是扩展机(extended machine)/虚拟机(virtual machine)。<br>在裸机上添加：设备管理、文件管理、存储管理（包括内存和外存）、处理机管理（针对CPU）；<br>– 另外，为合理组织工作流程：作业管理、进程管理</p>
<p>– 通道：用于控制I/O设备与内存间的数据传输。启动后可<br>独立于CPU运行，实现CPU与I/O的并行。<br>• 通道有专用的I/O处理器，可与CPU并行工作<br>• 可实现 I/O联机处理<br>– 中断是指CPU在收到外部中断信号后，停止原来工作，转<br>去处理该中断事件，完毕后回到原来断点继续工作。<br>• 中断处理过程：中断请求，中断响应，中断点（暂停当前任务并<br>保存现场），中断处理例程，中断返回（恢复中断点的现场并继续原<br>有任务</p>
<p>3、通道和中断技术<br>通道：用于控制I/O设备与内存间的数据传输。启动后可<br>独立于CPU运行，实现CPU与I/O的并行。 </p>
<p>中断是指CPU在收到外部中断信号后，停止原来工作，转<br>去处理该中断事件，完毕后回到原来断点继续工作。<br>• 中断处理过程：中断请求，中断响应，中断点（暂停当前任务并<br>保存现场），中断处理例程，中断返回（恢复中断点的现场并继续原<br>有任务</p>
<p>3.1、手工操作<br>计算机的工作特点<br>• 用户独占全机：不出现资源被其他用户占用，资源利<br>用率低；<br>• CPU等待用户：计算前，手工装入纸带或卡片；计算完<br>成后，手工卸取纸带或卡片；CPU利用率低；</p>
<p>3.2、单道批处理系统<br>联机批处理：输入输出设备和主机直接相连，串行工作<br>脱机批处理：利用卫星机完成输入输出功能。主机与卫星机可<br>并行工作。<br>– 卫星机：完成面向用户的输入输出（纸带或卡<br>片），中间结果暂存在磁带或磁盘上。<br>– 优点：同一批内各作业的自动依次更替，改善了<br>主机CPU和I/O设备的使用效率，提高了吞吐量。<br>– 缺点：磁带或磁盘需要人工装卸，作业需要人工<br>分类，监督程序易遭到用户程序的破坏（由人工干预<br>才可恢复）</p>
<p>3.3 多道批处理系统<br>多道批处理的运行特征<br>• 多道：内存中同时存放几个作业；<br>• 宏观上并行运行：都处于运行状态，但都未运行完；<br>• 微观上串行运行：各作业交替使用CPU；<br>在当前运行的作业需作I/O处理时，CPU转而执行<br>另一个作业。<br>优点：<br>• 资源利用率高：CPU和内存利用率较高；<br>• 作业吞吐量大：单位时间内完成的工作总量大；<br>– 缺点：<br>• 用户交互性差：整个作业完成后或中间出错时，<br>才与用户交互，不利于调试和修改；<br>• 作业平均周转时间长：短作业的周转时间显著<br>增长；</p>
<p>3.4 分 时 系 统<br>许多个联机用户同时使用一台计算机系统进行计算的操作<br>系统称分时操作系统<br>系统把中央处理器的时间划分成时间片 ，按时间片轮流<br>把处理机分配给联机作业<br>– “分时”的含义分时是指多个用户分享使用同一台计算机。<br>多个程序分时共享硬件和软件资源<br>– 人机交互性好：在调试和运行程序时由用户自己<br>操作。<br>– 共享主机：多个用户同时使用。<br>– 用户独立性：对每个用户而言好象独占主机</p>
<p>3.5 实 时 系 统<br>– 要求：响应时间短，在规定的时间之内（s, ms,<br>us）；系统可靠性高</p>
<p>3.6 通用操作系统<br>目前的操作系统，通常具有分时、实时和批处理<br>功能，又称作通用操作系统。</p>
<p>4、操作系统的分类<br>4.1 批处理操作系统<br>批处理系统中作业处理及状态：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/op3.png?raw=true" alt="Image text"></p>
<p>单道和多道批处理的比较<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/op4.png?raw=true" alt="Image text"></p>
<p>– 多道程序系统和多重处理系统(multi-processing<br>system)的区别：<br>• 前者指多个程序同时在内存中交替运行<br>• 后者指多个处理器</p>
<p>多道批处理系统上的技术<br>– 作业调度：作业的现场保存和恢复－－上下文切换<br>– 资源共享：资源的竞争和同步－－互斥(exclusion)<br>和同步(synchronization)机制<br>– 内存使用：提高内存使用效率（为当前由CPU执行<br>的程序提供足够的内存）－－覆盖(overlay)，交换<br>(swap)和虚拟存储(virtual memory)<br>– 内存保护：系统存储区和各应用程序存储区不可冲<br>突－－存储保护</p>
<p>4.2 分时操作系统<br>– 多路性：多个用户同时工作。<br>– 独立性：各用户独立操作，互不干扰。<br>– 交互性：系统能及时对用户的操作进行响应，显<br>著提高调试和修改程序的效率：缩短了周转时间。<br>（对批处理的改进）</p>
<p>4.3 实时操作系统<br>– 实时操作系统主要用于过程控制、事务处理等有<br>实时要求的领域，其主要特征是实时性和可靠性</p>
<p>5、 操作系统的特征<br>5.1 并 发 ( c o n c u r r e n c y )<br>– 多个事件在同一时间段内发生。操作系统是一个并<br>发系统，各进程间的并发，系统与应用间的并发。操作<br>系统要完成这些并发过程的管理。并行(parallel)是指<br>在同一时刻发生。<br>– 在多道程序处理时，宏观上并发，微观上交替执行<br>（在单处理器情况下）。<br>– 程序的静态实体是可执行文件，而动态实体是进程<br>（或称作任务），并发指的是进程。</p>
<p> 5.2 共 享 (sharing)<br> 多个进程共享有限的计算机系统资源。操作系统要<br>对系统资源进行合理分配和使用。资源在一个时间段内<br>交替被多个进程所用。<br>– 互斥共享（如视频设备）：资源分配后到释放前，<br>不能被其他进程所用</p>
<p>5.3 虚 拟 (virtual)<br>– 一个物理实体映射为若干个对应的逻辑实体－－分<br>时或分空间。虚拟是操作系统管理系统资源的重要手段，<br>可提高资源利用率</p>
<p>5.4 异步性 ( asynchronism )<br>– 也称不确定性，指进程的执行顺序和执行时间的不<br>确定性；<br>– 进程的运行速度不可预知：分时系统中，多个进程<br>并发执行，程序是以走走停停的方式运行的。系统中的<br>每个程序何时执行，执行顺序，完成时间都是不确定的。</p>
<p>6、操作系统的功能<br>6.1 处 理 机 管 理<br>– 完成处理机资源的分配调度等功能。处理机调度的<br>单位可为进程或线程。<br>– 进程控制：创建、撤销、状态转换<br>– 进程同步：对并发执行的进程进行协调<br>– 进程通信：负责完成进程间的信息交换<br>– 进程调度：按一定算法进行处理机分配</p>
<p>6.2 存 储 管 理<br>– 内存分配：按一定的策略分配内存并负责回收<br>– 内存保护：保证进程间互不干扰、相互保密<br>– 地址变换：进程逻辑地址到内存物理地址的映射；<br>– 内存扩充：为允许大型作业或多个作业运行，借助<br>虚拟技术获得更大逻辑内存的效果；</p>
<p>6.3 设备管理<br>– 设备分配：为了使设备与主机并行工作，一定的分<br>配原则对设备进行分配，常采用缓冲技术和虚拟技术<br>– 设备传输控制：实现物理的输入/输出操作<br>– 设备独立性：用户向系统申请的设备和实际操作的<br>设备无关</p>
<p>6.4 文 件 管 理<br>– 文件存储空间管理：存储空间的分配和回收。<br>– 目录管理：解决信息检索问题。<br>– 文件操作管理：实现文件的操作，负责完成数据的<br>读写<br>– 文件保护：提供文件保护功能，防止文件遭到破坏</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/27/操作系统概述/" data-id="cjuceyeyj0012fgs611chjqpv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计网-应用层" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/27/计网-应用层/" class="article-date">
  <time datetime="2019-03-27T11:43:49.837Z" itemprop="datePublished">2019-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/27/计网-应用层/">计网-应用层</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、 域名系统 DNS (Domain Name System)<br>互联网采用了层次树状结构的命名方法。<br>任何一个连接在互联网上的主机或路由器，都有一个唯一的层次结构的名字，即域名。<br>域名的结构由标号序列组成，各标号之间用点隔开： … . 三级域名 . 二级域名 . 顶级域名</p>
<p>(1) 国家顶级域名 nTLD<br>    .cn 表示中国，<br>    .us 表示美国，<br>    .uk 表示英国，等等。</p>
<p>(2) 通用顶级域名 gTLD<br>    最早的顶级域名是：<br>    .com    （公司和企业）<br>    .net    （网络服务机构<br>    .org    （非赢利性组织）<br>    .edu    （美国专用的教育机构）<br>    .gov    （美国专用的政府部门）<br>    .mil    （美国专用的军事部门）<br>    .int    （国际组织）</p>
<p>(3) 基础结构域名 (infrastructure domain)<br>    这种顶级域名只有一个，即 arpa，<br>    用于反向域名解析，因此又称为反向域名。</p>
<p>互联网的域名空间 ：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netapp1.png?raw=true" alt="Image text"></p>
<p>DNS 服务器的管辖范围不是以“域”为单位，而是以“区”为单位。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netapp2.png?raw=true" alt="Image text"></p>
<p>域名服务器有以下四种类型<br>根域名服务器 :在互联网上共有 13 个不同 IP 地址的根域名服务器，它们的名字是用一个英文字母命名，从 a  一直到 m（前 13 个字母）。<br>根域名服务器共有 13 套装置，不是 13 个机器。到2016年2月，全世界已经在 588 个地点安装了根域名服务器，使世界上大部分 DNS 域名服务器都能就近找到一个根域名服务器。 </p>
<p>顶级域名服务器 :级域名服务器（即 TLD 服务器）负责管理在该顶级域名服务器注册的所有二级域名。<br>权限域名服务器 :负责一个区的域名服务器。</p>
<p>本地域名服务器 :本地域名服务器对域名系统非常重要。<br>当一个主机发出 DNS 查询请求时，这个查询请求报文就发送给本地域名服务器。每一个互联网服务提供者 ISP，或一个大学，甚至一个大学里的系，都可以拥有一个本地域名服务器，<br>这种域名服务器有时也称为默认域名服务器。 </p>
<p>2、文件传送协议<br>文件传送协议 FTP (File Transfer Protocol) 是互联网上使用得最广泛的文件传送协议。<br>文件传送协议 FTP 只提供文件传送的一些基本的服务，它使用 TCP 可靠的运输服务。</p>
<p>FTP 使用的两个 TCP 连接<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netapp3.png?raw=true" alt="Image text"></p>
<p>3、远程终端协议 TELNET<br>TELNET 是一个简单的远程终端协议，也是互联网的正式标准。<br>TELNET 能将用户的击键传到远地主机，同时也能将远地主机的输出通过 TCP 连接返回到用户屏幕。这种服务是透明的，因为用户感觉到好像键盘和显示器是直接连在远地主机上。 </p>
<p>4、万维网 WWW<br>万维网 WWW (World Wide Web)是一个大规模的、联机式的信息储藏所。<br>万维网用链接的方法能非常方便地从互联网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。<br>这种访问方式称为“链接”。<br>使用统一资源定位符 URL (Uniform Resource Locator) 来标志万维网上的各种文档。<br>使每一个文档在整个互联网的范围内具有唯一的标识符 URL。<br>在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是超文本传送协议 HTTP (HyperText Transfer Protocol)。<br>HTTP 是一个应用层协议，它使用 TCP 连接进行可靠的传送。 </p>
<p>5、超文本传送协议 HTTP<br>从层次的角度看，HTTP 是面向事务的(transaction-oriented)应用层协议，它是万维网上能够可靠地交换文件（包括文本、声音、图像等各种多媒体文件）的重要基础。<br>HTTP 是面向事务的客户服务器协议。<br>HTTP 1.0 协议是无状态的 (stateless)。<br>HTTP 协议本身也是无连接的，虽然它使用了面向连接的 TCP 向上提供的服务。HTTP/1.1 协议使用持续连接 (persistent connection)。<br>万维网服务器在发送响应后仍然在一段时间内保持这条连接，使同一个客户（浏览器）和该服务器可以继续在这条连接上传送后续的 HTTP 请求报文和响应报文。<br>这并不局限于传送同一个页面上链接的文档，而是只要这些文档都在同一个服务器上就行。</p>
<p>代理服务器 (proxy server) 又称为万维网高速缓存 (Web cache)，它代表浏览器发出 HTTP 请求。</p>
<p>HTTP 的报文结构 HTTP 有两类报文：<br>请求报文——从客户向服务器发送请求报文。<br>响应报文——从服务器到客户的回答。<br>由于 HTTP 是面向正文的 (text-oriented)，因此在报文中的每一个字段都是一些 ASCII 码串，因而每个字段的长度都是不确定的。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netapp4.png?raw=true" alt="Image text"></p>
<p>状态码都是三位数字<br>1xx 表示通知信息的，如请求收到了或正在进行处理。<br>2xx 表示成功，如接受或知道了。<br>3xx 表示重定向，表示要完成请求还必须采取进一步的行动。<br>4xx 表示客户的差错，如请求中有错误的语法或不能完成。<br>5xx 表示服务器的差错，如服务器失效无法完成请求。</p>
<p>6、电子邮件<br>发送邮件的协议：SMTP<br>读取邮件的协议：POP3 和 IMAP<br>MIME 在其邮件首部中说明了邮件的数据类型(如文本、声音、图像、视像等)，使用 MIME 可在邮件中同时传送多种类型的数据。 </p>
<p>7、动态主机配置协议 DHCP<br>为了将软件协议做成通用的和便于移植，协议软件的编写者把协议软件参数化。这就使得在很多台计算机上使用同一个经过编译的二进制代码成为可能。<br>需要配置的项目<br>    (1) IP 地址<br>    (2) 子网掩码<br>    (3) 默认路由器的 IP 地址<br>    (4) 域名服务器的 IP 地址<br>这些信息通常存储在一个配置文件中，计算机在引导过程中可以对这个文件进行存取。<br>互联网广泛使用的动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用连网 (plug-and-play networking) 的机制。<br>这种机制允许一台计算机加入新的网络和获取IP 地址而不用手工参与。<br>DHCP 服务器分配给 DHCP 客户的 IP 地址的临时的，因此 DHCP 客户只能在一段有限的时间内使用这个分配到的 IP 地址。DHCP 协议称这段时间为租用期。<br>租用期的数值应由 DHCP 服务器自己决定</p>
<p>8、简单网络管理协议 SNMP<br>网络管理包括对硬件、软件和人力的使用、综合与协调，以便对网络资源进行监视、测试、配置、分析、评价和控制，这样就能以合理的价格满足网络的一些需求，如实时运行性能，服务质量等。网络管理常简称为网管。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/27/计网-应用层/" data-id="cjuceyexp000sfgs6d6rusy6r" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计网-传输层" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/27/计网-传输层/" class="article-date">
  <time datetime="2019-03-27T03:36:45.875Z" itemprop="datePublished">2019-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/27/计网-传输层/">计网-传输层</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、传输层与网络层的主要区别<br>网络层是为主机之间提供逻辑通信，<br>而运输层为应用进程之间提供端到端的逻辑通信。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra1.png?raw=true" alt="Image text"></p>
<p>2、 运输层的两个主要协议<br>(1) 用户数据报协议 UDP (User Datagram Protocol)<br> UDP 传送的数据单位协议是 UDP 报文或用户数据报。<br>UDP：一种无连接协议<br>提供无连接服务。<br>在传送数据之前不需要先建立连接。<br>传送的数据单位协议是 UDP 报文或用户数据报。<br>对方的运输层在收到 UDP 报文后，不需要给出任何确认。<br>虽然 UDP 不提供可靠交付，但在某些情况下 UDP 是一种最有效的工作方式。</p>
<p>UDP 的主要特点：<br>(1) UDP 是无连接的，发送数据之前不需要建立连接，，因此减少了开销和发送数据之前的时延。<br>(2) UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的连接状态表。<br>(3) UDP 是面向报文的。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。UDP 一次交付一个完整的报文。<br>(4) UDP 没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很适合多媒体通信的要求。<br>(5) UDP 支持一对一、一对多、多对一和多对多的交互通信。<br>(6) UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短。</p>
<p>UDP 的首部格式<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra3.png?raw=true" alt="Image text"><br>伪首部仅仅是为了计算检验和<br>请注意，虽然在 UDP 之间的通信要用到其端口号，但由于 UDP 的通信是无连接的，因此不需要使用套接字。</p>
<p>(2) 传输控制协议 TCP (Transmission Control Protocol)<br>TCP 传送的数据单位协议是 TCP 报文段(segment)。<br>TCP：一种面向连接的协议<br>提供面向连接的服务。<br>传送的数据单位协议是 TCP 报文段 (segment)。<br>TCP 不提供广播或多播服务。<br>由于 TCP 要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。</p>
<p>TCP 最主要的特点<br>TCP 是面向连接的运输层协议。<br>每一条 TCP 连接只能有两个端点 (endpoint)，每一条 TCP 连接只能是点对点的（一对一）。<br>TCP 提供可靠交付的服务。<br>TCP 提供全双工通信。<br>面向字节流<br>TCP 中的“流”(stream)指的是流入或流出进程的字节序列。<br>“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块，但 TCP 把应用程序交下来的数据看成仅仅是一连串无结构的字节流。</p>
<p>TCP 面向流的概念<br>TCP 不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系。<br>但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。<br> <img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra4.png?raw=true" alt="Image text"><br>注 意<br>TCP 连接是一条虚连接而不是一条真正的物理连接。<br>TCP 对应用进程一次把多长的报文发送到TCP 的缓存中是不关心的。<br>TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。<br>TCP 可把太长的数据块划分短一些再传送。<br>TCP 也可等待积累有足够多的字节后再构成报文段发送出去。<br>TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字 (socket) 或插口。<br>端口号拼接到 (contatenated with) IP 地址即构成了套接字。 </p>
<ul>
<li>socket = (IP地址 : 端口号)</li>
</ul>
<p>每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定。即：</p>
<p>TCP 连接 ::= {socket1, socket2} = {(IP1: port1)，(IP2: port2)}</p>
<p>3、两大类端口<br>(1) 服务器端使用的端口号<br>熟知端口，数值一般为 0~1023。<br>登记端口号，数值为 1024~49151，为没有熟知端口号的应用程序使用的。使用这个范围的端口号必须在 IANA 登记，以防止重复。<br>(2) 客户端使用的端口号<br>又称为短暂端口号，数值为 49152~65535，留给客户进程选择暂时使用。<br>当服务器进程收到客户进程的报文时，就知道了客户进程所使用的动态端口号。通信结束后，这个端口号可供其他客户进程以后使用。<br>常用端口号：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra2.png?raw=true" alt="Image text"></p>
<p>4、可靠传输的工作原理<br>停止等待协议<br>“停止等待”就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。<br>全双工通信的双方既是发送方也是接收方。</p>
<p>（1）无差错情况<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra5.png?raw=true" alt="Image text"><br>（2）出现差错<br>在接收方 B 会出现两种情况：<br>B 接收 M1 时检测出了差错，就丢弃 M1，其他什么也不做（不通知 A 收到有差错的分组）。<br>M1 在传输过程中丢失了，这时 B 当然什么都不知道，也什么都不做。<br>在这两种情况下，B 都不会发送任何信息。</p>
<p>解决方法：<br>超时重传<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra6.png?raw=true" alt="Image text"></p>
<p>确认丢失和确认迟到<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra7.png?raw=true" alt="Image text"><br>在发送完一个分组后，必须暂时保留已发送的分组的副本，以备重发。<br>分组和确认分组都必须进行编号。<br>超时计时器的重传时间应当比数据在分组传输的平均往返时间更长一些。 </p>
<p>自动重传请求 ARQ协议<br>通常 A 最终总是可以收到对所有发出的分组的确认。如果 A 不断重传分组但总是收不到确认，就说明通信线路太差，不能进行通信。<br>使用上述的确认和重传机制，我们就可以在不可靠的传输网络上实现可靠的通信。<br>像上述的这种可靠传输协议常称为自动重传请求 ARQ  (Automatic Repeat reQuest)。意思是重传的请求是自动进行的，接收方不需要请求发送方重传某个出错的分组。</p>
<p>连续 ARQ 协议（滑动窗口协议）<br>是 TCP 协议的精髓所在。<br>发送方维持的发送窗口，它的意义是：位于发送窗口内的分组都可连续发送出去，而不需要等待对方的确认。这样，信道利用率就提高了。<br>连续 ARQ 协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra8.png?raw=true" alt="Image text"></p>
<p>累积确认<br>接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。<br>优点：容易实现，即使确认丢失也不必重传。<br>缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。</p>
<p>Go-back-N（回退 N）<br>如果发送方发送了前 5 个分组，而中间的第 3 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。<br>这就叫做 Go-back-N（回退 N），表示需要再退回来重传已发送过的 N 个分组。<br>可见当通信线路质量不好时，连续 ARQ 协议会带来负面的影响。 </p>
<p>TCP 可靠通信的具体实现<br>TCP 连接的每一端都必须设有两个窗口——一个发送窗口和一个接收窗口。<br>TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段。<br>TCP 两端的四个窗口经常处于动态变化之中。<br>TCP连接的往返时间 RTT 也不是固定不变的。需要使用特定的算法估算较为合理的重传时间。  </p>
<p>TCP 报文段的首部格式<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra9.png?raw=true" alt="Image text"><br>01 源端口和目的端口字段——各占 2 字节。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。<br>02 序号字段——占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。<br>03 确认号字段——占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。<br>数据偏移（即首部长度）——占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。<br>04 紧急 URG —— 当 URG  1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。<br>05 确认 ACK —— 只有当 ACK  1 时确认号字段才有效。当 ACK  0 时，确认号无效。<br>06 推送 PSH (PuSH) —— 接收 TCP 收到 PSH = 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。<br>07 复位 RST (ReSeT) —— 当 RST  1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。<br>08 同步 SYN —— 同步 SYN = 1 表示这是一个连接请求或连接接受报文。<br>09 终止 FIN (FINish) —— 用来释放一个连接。FIN  1 表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。<br>10 窗口字段 —— 占 2 字节，用来让对方设置发送窗口的依据，单位为字节。<br>检验和 —— 占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。<br>11 填充字段 —— 这是为了使整个首部长度是 4 字节的整数倍。</p>
<p>5、TCP 可靠传输的实现<br>滑动窗口：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra10.png?raw=true" alt="Image text"><br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra11.png?raw=true" alt="Image text"></p>
<p>发送缓存用来暂时存放：<br>发送应用程序传送给发送方 TCP 准备发送的数据；<br>TCP 已发送出但尚未收到确认的数据。<br>接收缓存用来暂时存放：<br>按序到达的、但尚未被接收应用程序读取的数据；<br>不按序到达的数据。 </p>
<p>超时重传时间的选择<br>TCP 采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是报文段的往返时间 RTT。<br>超时重传时间 RTO<br>RTO (Retransmission Time-Out) 应略大于上面得出的加权平均往返时间 RTTS。<br>RFC 2988 建议使用下式计算 RTO：<br>RTO = RTTS + 4 * RTTD<br>RTTD 是 RTT 的偏差的加权平均值。</p>
<p>修正的 Karn 算法<br>报文段每重传一次，就把 RTO 增大一些：<br>新的 RTO = a * (旧的 RTO) </p>
<p>系数a的典型值是 2 。<br>当不再发生报文段的重传时，才根据报文段的往返时延更新平均往返时延 RTT 和超时重传时间 RTO 的数值。</p>
<p>6、TCP 的流量控制<br>利用可变窗口进行流量控制<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra12.png?raw=true" alt="Image text"><br>TCP 为每一个连接设有一个持续计时器  (persistence timer) 。<br>只要 TCP 连接的一方收到对方的零窗口通知，就启动该持续计时器。<br>若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带 1 字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。<br>若窗口仍然是零，则收到这个报文段的一方就重新设置持续计时器。</p>
<p>7、TCP 的拥塞控制<br>拥塞：在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。</p>
<p>拥塞控制与流量控制的区别<br>拥塞控制就是防止过多的数据注入到网络中，使网络中的路由器或链路不致过载。<br>拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。<br>拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。</p>
<p>流量控制往往指点对点通信量的控制，是个端到端的问题（接收端控制发送端）。<br>流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 </p>
<p>TCP 的拥塞控制方法<br>TCP 采用基于窗口的方法进行拥塞控制。该方法属于闭环控制方法。<br>TCP发送方维持一个拥塞窗口 CWND (Congestion Window)<br>拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。<br>发送端利用拥塞窗口根据网络的拥塞情况调整发送的数据量。<br>所以，发送窗口大小不仅取决于接收方公告的接收窗口，还取决于网络的拥塞状况，所以真正的发送窗口值为：<br>真正的发送窗口值 = Min(公告窗口值，拥塞窗口值)</p>
<p>TCP拥塞控制算法<br>(1)慢开始 (Slow start)<br>用来确定网络的负载能力。<br>算法的思路：由小到大逐渐增大拥塞窗口数值。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra13.png?raw=true" alt="Image text"><br>慢开始门限 ssthresh（状态变量）：防止拥塞窗口cwnd 增长过大引起网络拥塞。<br>拥塞窗口 cwnd  控制方法：在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个 最大报文段 SMSS (Sender Maximum Segment Size) 的数值。<br>拥塞窗口cwnd每次的增加量 = min (N, SMSS)</p>
<p>慢开始门限 ssthresh 的用法如下：<br>当 cwnd &lt; ssthresh 时，使用慢开始算法。<br>当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。</p>
<p>(2)拥塞避免算法<br>让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。<br>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（重传定时器超时）：<br>ssthresh = max(cwnd/2，2)<br>cwnd = 1<br>执行慢开始算法<br>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 </p>
<p>慢开始和拥塞避免算法的实现举例<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra14.png?raw=true" alt="Image text"></p>
<p>(3)快重传算法<br>采用快重传FR (Fast Retransmission) 算法可以让发送方尽早知道发生了个别报文段的丢失。发送方只要一连收到三个重复确认，就知道接收方确实没有收到报文段，因而应当立即进行重传（即“快重传”），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。<br>快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。<br>快重传举例<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra15.png?raw=true" alt="Image text"></p>
<p>（4）快恢复算法<br>当发送端收到连续三个重复的确认时，由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，而是执行快恢复算法 FR (Fast Recovery) 算法：<br>01 慢开始门限 ssthresh = 当前拥塞窗口 cwnd / 2 ；<br>02 新拥塞窗口 cwnd = 慢开始门限 ssthresh ；<br>03 开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra16.png?raw=true" alt="Image text"></p>
<p>TCP拥塞控制流程图<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra17.png?raw=true" alt="Image text"></p>
<p>发送窗口的上限值<br>发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定：<br>发送窗口的上限值  Min [rwnd, cwnd]</p>
<p>8、 TCP 的运输连接管理<br>TCP 是面向连接的协议。<br>运输连接有三个阶段：<br>连接建立<br>数据传送<br>连接释放<br>运输连接的管理就是使运输连接的建立和释放都能正常地进行。</p>
<p>（1）TCP 的连接建立：采用三次（三报文）握手<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra18.png?raw=true" alt="Image text"></p>
<p>（2）TCP 的连接释放：四次（四报文）握手。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/nettra19.png?raw=true" alt="Image text"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/27/计网-传输层/" data-id="cjuceyez10018fgs69ahuhexd" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计网-网络层" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/26/计网-网络层/" class="article-date">
  <time datetime="2019-03-26T11:50:34.168Z" itemprop="datePublished">2019-03-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/26/计网-网络层/">计网-网络层</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、网际协议 IP 是 TCP/IP 体系中两个最主要的协议之一。<br>与 IP 协议配套使用的还有三个协议：<br>地址解析协议 ARP<br>    (Address Resolution Protocol)<br>网际控制报文协议 ICMP<br>   (Internet Control Message Protocol)<br>网际组管理协议 IGMP<br>   (Internet Group Management Protocol)</p>
<p>网际层的 IP 协议及配套协议:<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet1.png?raw=true" alt="Image text"></p>
<p>2、IP 地址就是给每个连接在互联网上的主机（或路由器）分配一个在全世界范围是唯一的 32 位的标识符。</p>
<p>3、<br>IP地址结构:<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet2.png?raw=true" alt="Image text"></p>
<p>几类IP地址：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet3.png?raw=true" alt="Image text"></p>
<p>点分十进制表示：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet4.png?raw=true" alt="Image text"></p>
<p>常用的三种类别的 IP 地址<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet5.png?raw=true" alt="Image text"></p>
<p>一般不使用的特殊的 IP 地址<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet6.png?raw=true" alt="Image text"></p>
<p>(1) IP 地址是一种分等级的地址结构。<br>(2) 实际上 IP 地址是标志一个主机（或路由器）和一条链路的接口<br>(3) 用转发器或网桥连接起来的若干个局域网仍为一个网络，因此这些局域网都具有同样的网络号 net-id。<br>(4) 所有分配到网络号 net-id 的网络，无论是范围很小的局域网，还是可能覆盖很大地理范围的广域网，都是平等的。<br>（5）路由器总是具有两个或两个以上的 IP 地址。路由器的每一个接口都有一个不同网络号的 IP 地址。</p>
<p>4、IP 地址与硬件地址<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet7.png?raw=true" alt="Image text"></p>
<p>5、地址解析协议 ARP<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet8.png?raw=true" alt="Image text"><br>ARP 作用：<br>从网络层使用的 IP 地址，解析出在数据链路层使用的硬件地址。</p>
<p>不管网络层使用的是什么协议，在实际网络的链路上传送数据帧时，最终还是必须使用硬件地址。</p>
<p>每一个主机都设有一个 ARP 高速缓存 (ARP cache)，里面有所在的局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。</p>
<p>ARP工作过程：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet9.png?raw=true" alt="Image text"></p>
<p>ARP 是解决同一个局域网上的主机或路由器的 IP 地址和硬件地址的映射问题。</p>
<p>5、IP数据报格式：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet10.png?raw=true" alt="Image text"><br>（1）版本——占 4 位，指 IP 协议的版本。目前的 IP 协议版本号为 4 (即 IPv4)。<br>（2）首部长度——占 4 位，可表示的最大数值是 15 个单位(一个单位为 4 字节)，因此 IP 的首部长度的最大值是 60 字节。<br>（3）总长度——占 16 位，指首部和数据之和的长度，单位为字节，因此数据报的最大长度为 65535 字节。总长度必须不超过最大传送单元 MTU。<br>（4）标识(identification) ——占 16 位，它是一个计数器，用来产生 IP 数据报的标识。<br>（5）标志(flag) ——占 3 位，目前只有前两位有意义。标志字段的最低位是 MF (More Fragment)。MF = 1 表示后面“还有分片”。MF = 0 表示最后一个分片。标志字段中间的一位是 DF (Don’t Fragment) 。只有当 DF = 0 时才允许分片。<br>（6）片偏移——占13 位，指出：较长的分组在分片后某片在原分组中的相对位置。片偏移以 8 个字节为偏移单位。<br>（7）生存时间——占8 位，记为 TTL (Time To Live)，指示数据报在网络中可通过的路由器数的最大值。<br>（8）协议——占8 位，指出此数据报携带的数据使用何种协议，以便目的主机的 IP 层将数据部分上交给那个处理过程<br>（9）首部检验和——占16 位，只检验数据报的首部，不检验数据部分。这里不采用 CRC 检验码而采用简单的计算方法。</p>
<p>6、划分子网<br>划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的网络。从主机号借用若干个位作为子网号 subnet-id，而主机号 host-id 也就相应减少了若干个位。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet11.png?raw=true" alt="Image text"></p>
<p>7、子网掩码<br>使用子网掩码 (subnet mask) 可以找出 IP 地址中的子网部分。<br>IP 地址的各字段和子网掩码<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet12.png?raw=true" alt="Image text"></p>
<p>(IP 地址) AND (子网掩码) =网络地址</p>
<p>8、无分类编址 CIDR<br>CIDR使用各种长度的“网络前缀”(network-prefix)来代替分类地址中的网络号和子网号。<br>IP 地址从三级编址（使用子网掩码）又回到了两级编址。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet13.png?raw=true" alt="Image text"><br>CIDR 使用“斜线记法”(slash notation)，它又称为 CIDR 记法，即在 IP 地址面加上一个斜线“/”，然后写上网络前缀所占的位数，128.14.32.0/20 表示的地址块共有 212 个地址（因为斜线后面的 20 是网络前缀的位数，所以这个地址的主机号是 12 位）。</p>
<p>9、一个 CIDR 地址块可以表示很多地址，这种地址的聚合常称为路由聚合，路由聚合也称为构成超网 (supernetting)。</p>
<p>10、 网际控制报文协议 ICMP<br>ICMP报文格式：<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet14.png?raw=true" alt="Image text"><br>ICMP 报文的种类有两种，即 ICMP 差错报告报文和 ICMP 询问报文。<br>ICMP 差错报告报文共有 4 种<br>终点不可达<br>时间超过<br>参数问题<br>改变路由（重定向）(Redirect)  </p>
<p>ICMP 询问报文有两种<br>回送请求和回答报文<br>时间戳请求和回答报文</p>
<p>PING 用来测试两个主机之间的连通性。使用了 ICMP 回送请求与回送回答报文。是应用层直接使用网络层 ICMP 的例子，它没有通过运输层的 TCP 或UDP。</p>
<p>11、互联网的路由选择协议<br>（1）内部网关协议 IGP (Interior Gateway Protocol)<br>在一个自治系统内部使用的路由选择协议。目前这类路由选择协议使用得最多，如 RIP 和 OSPF 协议。<br>（1.1）RIP 是一种分布式的、基于距离向量的路由选择协议。能使用的最大距离为 15（16 表示不可达）。</p>
<p>RIP协议更新路由器条件：<br>01 加入新网络<br>02 相邻路由器的路由改变了<br>03 有更短的最短路径</p>
<p>已知路由器 R6 有表 4-9(a) 所示的路由表。现在收到相邻路由器 R4 发来的路由更新信息，如表 4-9(b) 所示。试更新路由器 R6 的路由表。<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet15.png?raw=true" alt="Image text"></p>
<p>（2）外部网关协议 EGP (External Gateway Protocol)<br>若源站和目的站处在不同的自治系统中，当数据报传到一个自治系统的边界时，就需要使用一种协议将路由选择信息传递到另一个自治系统中。这样的协议就是外部网关协议 EGP。在外部网关协议中目前使用最多的是 BGP-4。</p>
<p>12、路由器的构成<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet16.png?raw=true" alt="Image text"></p>
<p>13、虚拟专用网 VPN和网络地址转换 NAT<br>（1）虚拟专用网 VPN：利用公用的互联网作为本机构各专用网之间的通信载体，这样的专用网又称为虚拟专用网VPN (Virtual Private Network)。</p>
<p>（2）网络地址转换 NAT<br><img src="https://github.com/Tingzi123/blog/blob/master/_posts/picture/netnet17.png?raw=true" alt="Image text"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/26/计网-网络层/" data-id="cjuceyexo000rfgs6scq0vtjp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/04/11/设计模式-单例模式/">设计模式-单例模式</a>
          </li>
        
          <li>
            <a href="/2019/04/11/设计模式-抽象工厂模式/">设计模式-抽象工厂模式</a>
          </li>
        
          <li>
            <a href="/2019/04/11/设计模式-工厂模式/">设计模式-工厂模式</a>
          </li>
        
          <li>
            <a href="/2019/04/11/设计模式-代理模式/">设计模式-代理模式</a>
          </li>
        
          <li>
            <a href="/2019/04/10/设计模式-备忘录模式/">设计模式-备忘录模式</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>